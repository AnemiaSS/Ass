<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Detection with Camera Controls</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background: #faf8f8;
            text-align: center;
            margin: 0;
            padding: 0;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
        }

        .container {
            background-color: rgba(255, 255, 255, 0.9);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            width: 100%;
            max-width: 720px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        .main-canvas {
            border-radius: 10px;
            max-width: 100%;
            max-height: 400px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
            margin: 15px 0;
        }

        .camera-controls {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
        }

        .camera-btn {
            background-color: #f5b62a;
            color: white;
            padding: 8px 15px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .camera-btn:hover {
            background-color: #f07325;
        }

        .xx {
            position: absolute;
            top: 0;
            left: 0;
            margin: 10px;
        }
        h1 {
            font-weight: bold;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
            font-size: 24px;
            color: #5A3D9A;
            margin-bottom: 20px;
        }
    </style>
</head>

<body>
    <a class="xx">
        <img src="03.png" alt="‡∏õ‡πâ‡∏≤‡∏¢" style="width: 150px; height: 70px;">
    </a>
    <div class="container">
        <h1>‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå</h1>
        <div class="camera-controls">
            <button id="flipCamera" class="camera-btn">‡∏™‡∏•‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á</button>
        </div>
        <video id="video" autoplay playsinline></video>
        <canvas id="outputCanvas" class="main-canvas"></canvas>
        <button id="captureButton" class="camera-btn">üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û</button>
    </div>

    <script>
        let currentCamera = 'user';
        let faceMesh;
        let camera;
        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasCtx = canvasElement.getContext('2d');
        let currentLandmarks = null;

        async function startCamera() {
            try {
                if (videoElement.srcObject) {
                    videoElement.srcObject.getTracks().forEach(track => track.stop());
                }
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: currentCamera }
                });
                videoElement.srcObject = stream;
                await videoElement.play();

                if (!faceMesh) {
                    faceMesh = new FaceMesh({
                        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
                    });
                    faceMesh.setOptions({
                        maxNumFaces: 1,
                        refineLandmarks: true,
                        minDetectionConfidence: 0.5,
                        minTrackingConfidence: 0.5,
                    });
                    faceMesh.onResults(onResults);
                }

                if (camera) {
                    camera.stop();
                }
                camera = new Camera(videoElement, {
                    onFrame: async () => {
                        await faceMesh.send({ image: videoElement });
                    },
                    width: 640,
                    height: 480,
                });
                camera.start();
            } catch (err) {
                console.error('Error starting camera:', err);
                alert('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á');
            }
        }

        function switchCamera() {
            currentCamera = currentCamera === 'user' ? 'environment' : 'user';
            startCamera();
        }

        function onResults(results) {
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.restore();
        }

        document.getElementById('flipCamera').addEventListener('click', switchCamera);
        document.getElementById('captureButton').addEventListener('click', () => {
            const dataUrl = canvasElement.toDataURL('image/png');
            localStorage.setItem('capturedImage', dataUrl);
            window.location.href = "page5.html";
        });
        
        startCamera();
    </script>
</body>
</html>
