<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Eye Detection with Camera Controls</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background: #faf8f8;
            text-align: center;
            margin: 0;
            padding: 0;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
        }
        .container {
            background-color: rgba(255, 255, 255, 0.9);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            width: 90%;
            max-width: 720px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }
        .main-canvas {
            border-radius: 10px;
            width: 100%;
            height: auto;
            max-height: 400px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
            margin: 15px 0;
        }
        .camera-controls {
            display: flex;
            gap: 10px;
            margin-bottom: 15px;
        }
        .camera-btn {
            background-color: #f5b62a;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
            font-size: 1rem;
        }
        .camera-btn:hover {
            background-color: #f07325;
        }
        video {
            display: none;
        }
        .xx {
            position: absolute;
            top: 0;
            left: 0;
            margin: 10px;
        }
    </style>
</head>
<body>
    <a class="xx">
        <img src="03.png" alt="‡∏õ‡πâ‡∏≤‡∏¢" style="width: 150px; height: 70px;">
    </a>
    <div class="container">
        <h1>‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå</h1>
        <div class="camera-controls">
            <button id="flipCamera" class="camera-btn">‡∏™‡∏•‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á</button>
        </div>
        <video id="video" autoplay playsinline></video>
        <canvas id="outputCanvas" class="main-canvas"></canvas>
        <button id="captureButton" class="camera-btn">üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û</button>
    </div>

    <script>
        const videoElement = document.getElementById('video');
        const canvasElement = document.getElementById('outputCanvas');
        const canvasCtx = canvasElement.getContext('2d');
        let currentCamera = 'user';
        let faceMesh;
        let camera;
        let currentLandmarks;

        async function startCamera() {
            try {
                if (videoElement.srcObject) {
                    videoElement.srcObject.getTracks().forEach(track => track.stop());
                }
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: currentCamera, width: { ideal: 720 }, height: { ideal: 1280 } }
                });
                videoElement.srcObject = stream;
                await videoElement.play();
                if (!faceMesh) {
                    faceMesh = new FaceMesh({
                        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
                    });
                    faceMesh.setOptions({
                        maxNumFaces: 1,
                        refineLandmarks: true,
                        minDetectionConfidence: 0.5,
                        minTrackingConfidence: 0.5,
                    });
                    faceMesh.onResults(onResults);
                }
                if (camera) {
                    camera.stop();
                }
                camera = new Camera(videoElement, {
                    onFrame: async () => {
                        await faceMesh.send({ image: videoElement });
                    },
                    width: 720,
                    height: 1280,
                });
                camera.start();
            } catch (err) {
                console.error('Error starting camera:', err);
                alert('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á');
            }
        }

        function switchCamera() {
            currentCamera = currentCamera === 'user' ? 'environment' : 'user';
            startCamera();
        }

        function onResults(results) {
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                currentLandmarks = results.multiFaceLandmarks[0];
            }
        }

        function captureEyeRegion(landmarks, indices, scaleFactor) {
            const xCoords = indices.map(idx => landmarks[idx].x * canvasElement.width);
            const yCoords = indices.map(idx => landmarks[idx].y * canvasElement.height);
            const xMin = Math.min(...xCoords);
            const xMax = Math.max(...xCoords);
            const yMin = Math.min(...yCoords);
            const yMax = Math.max(...yCoords);
            const width = xMax - xMin;
            const height = yMax - yMin;
            const size = Math.max(width, height) * scaleFactor;
            const centerX = (xMin + xMax) / 2;
            const centerY = (yMin + yMax) / 2;
            return { x: centerX - size / 2, y: centerY - size / 2, size: size };
        }

        function storeCapturedImages(leftRegion, rightRegion) {
            const leftCanvas = document.createElement('canvas');
            const rightCanvas = document.createElement('canvas');
            leftCanvas.width = rightCanvas.width = leftRegion.size;
            leftCanvas.height = rightCanvas.height = rightRegion.size;
            leftCanvas.getContext('2d').drawImage(canvasElement, leftRegion.x, leftRegion.y, leftRegion.size, leftRegion.size, 0, 0, leftRegion.size, leftRegion.size);
            rightCanvas.getContext('2d').drawImage(canvasElement, rightRegion.x, rightRegion.y, rightRegion.size, rightRegion.size, 0, 0, rightRegion.size, rightRegion.size);
            localStorage.setItem('leftEyeImage', leftCanvas.toDataURL('image/png'));
            localStorage.setItem('rightEyeImage', rightCanvas.toDataURL('image/png'));
            window.location.href = "page5.html";
        }

        document.getElementById('flipCamera').addEventListener('click', switchCamera);
        document.getElementById('captureButton').addEventListener('click', () => {
            if (currentLandmarks) {
                const leftRegion = captureEyeRegion(currentLandmarks, [33, 133, 246, 161], 1.5);
                const rightRegion = captureEyeRegion(currentLandmarks, [263, 362, 466, 388], 1.5);
                storeCapturedImages(leftRegion, rightRegion);
            }
        });

        startCamera();
    </script>
</body>
</html>
